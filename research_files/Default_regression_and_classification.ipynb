{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680bc155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>released_day_of_year</th>\n",
       "      <th>streams</th>\n",
       "      <th>bpm</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>danceability_%</th>\n",
       "      <th>valence_%</th>\n",
       "      <th>energy_%</th>\n",
       "      <th>acousticness_%</th>\n",
       "      <th>instrumentalness_%</th>\n",
       "      <th>liveness_%</th>\n",
       "      <th>speechiness_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>141.381703</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>83</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>133.716286</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>140.003974</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>800.840817</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138</td>\n",
       "      <td>303.236322</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>23</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>307</td>\n",
       "      <td>91.473363</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>294</td>\n",
       "      <td>121.871870</td>\n",
       "      <td>166</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>307</td>\n",
       "      <td>73.513683</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>293</td>\n",
       "      <td>133.895612</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>308</td>\n",
       "      <td>96.007391</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>32</td>\n",
       "      <td>67</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>952 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     released_day_of_year     streams  bpm  key  mode  danceability_%  \\\n",
       "0                     195  141.381703  125    2     0              80   \n",
       "1                      82  133.716286   92    3     0              71   \n",
       "2                     181  140.003974  138    7     0              51   \n",
       "3                     235  800.840817  170    0     0              55   \n",
       "4                     138  303.236322  144    0     1              65   \n",
       "..                    ...         ...  ...  ...   ...             ...   \n",
       "947                   307   91.473363  144    0     0              60   \n",
       "948                   294  121.871870  166    8     0              42   \n",
       "949                   307   73.513683   92    3     0              80   \n",
       "950                   293  133.895612   97    3     0              82   \n",
       "951                   308   96.007391   90    6     1              61   \n",
       "\n",
       "     valence_%  energy_%  acousticness_%  instrumentalness_%  liveness_%  \\\n",
       "0           89        83              31                   0           8   \n",
       "1           61        74               7                   0          10   \n",
       "2           32        53              17                   0          31   \n",
       "3           58        72              11                   0          11   \n",
       "4           23        80              14                  63          11   \n",
       "..         ...       ...             ...                 ...         ...   \n",
       "947         24        39              57                   0           8   \n",
       "948          7        24              83                   1          12   \n",
       "949         81        67               4                   0           8   \n",
       "950         67        77               8                   0          12   \n",
       "951         32        67              15                   0          11   \n",
       "\n",
       "     speechiness_%  \n",
       "0                4  \n",
       "1                4  \n",
       "2                6  \n",
       "3               15  \n",
       "4                6  \n",
       "..             ...  \n",
       "947              3  \n",
       "948              6  \n",
       "949              6  \n",
       "950              5  \n",
       "951              5  \n",
       "\n",
       "[952 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## parameters  key and bpm have a least 20% infulence over the songs streams\n",
    "# predict key and bpm regargding all the other parameters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import date\n",
    "\n",
    "data = pd.read_csv(\"MAIN_DATASET_spotify2023.csv\")\n",
    "\n",
    "data.head()\n",
    "encoder = LabelEncoder()\n",
    "data[\"key\"] = encoder.fit_transform(data[\"key\"])\n",
    "data[\"mode\"] = encoder.fit_transform(data[\"mode\"])\n",
    "released_day_of_year = []\n",
    "\n",
    "for i in range(len(data.index)):\n",
    "    day_of_year = date(data['released_year'][i],\n",
    "                    data['released_month'][i],\n",
    "                    data['released_day'][i]).timetuple().tm_yday\n",
    "    released_day_of_year.append(day_of_year)\n",
    "\n",
    "# add new series to dataframe\n",
    "data.insert(len(data.columns), \"released_day_of_year\", released_day_of_year, True)\n",
    "\n",
    "data = data[[\"released_day_of_year\", \"streams\",'bpm','key', 'mode', 'danceability_%', 'valence_%', 'energy_%','acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%']]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[\"streams\"][i] = data[\"streams\"][i] / 1000000\n",
    "#data_standarized\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a50b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Train: 59.98 ,Validation:19.96 and Test dataset:20.06 \n"
     ]
    }
   ],
   "source": [
    "X = data.drop(\"streams\", axis = 1)\n",
    "y = data[\"streams\"]\n",
    "\n",
    "X_train, X_help, y_train, y_help = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_help, y_help, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "val_percent = (len(X_val)/(len(data)))*100\n",
    "test_percent = (len(X_test)/(len(data)))*100\n",
    "train_percent = (len(X_train)/(len(data)))*100\n",
    "print(f\"Percent of Train: {train_percent:.2f} ,Validation:{val_percent:.2f} and Test dataset:{test_percent:.2f} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478af46f",
   "metadata": {},
   "source": [
    "## Task 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46648798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rmse: 553.6714135282607, Mean:  306552.0341583822\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "weights_train = np.ones_like(y_train)\n",
    "np.random.seed(42)\n",
    "random_weights = np.random.rand(len(y_train))\n",
    "\n",
    "reg.fit(X_train, y_train, sample_weight=weights_train)\n",
    "y_pred_train = reg.predict(X_train)\n",
    "y_pred = reg.predict(X_val)\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_pred_train - y_train)**2))\n",
    "\n",
    "mean = mean_squared_error(y_train, y_pred_train)\n",
    "print(f\"Rmse: {rmse}, Mean:  {mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a22bb",
   "metadata": {},
   "source": [
    "##  Task3 neural regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f151cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rmse: 4736.018432041637, Mean:  22429870.58863813\n"
     ]
    }
   ],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=(5, 6, 5), random_state=50, max_iter=50, solver='sgd')\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred_train = reg.predict(X_train)\n",
    "y_pred = reg.predict(X_val)\n",
    "\n",
    "# and then try some customization, for example:\n",
    "#reg = MLPRegressor(hidden_layer_sizes=(15, 10, 5), random_state=1, max_iter=1000, solver='adam')\n",
    "\n",
    "#hidden_layer_sizes=(5, 100, 500) 75% \"sgd\" 81%\n",
    "#max_iter 11 best 83%\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_pred_train - y_train)**2))\n",
    "mean = mean_squared_error(y_train, y_pred_train)\n",
    "print(f\"Rmse: {rmse}, Mean:  {mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e3f23",
   "metadata": {},
   "source": [
    "## Task 4  Polynomial reggresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ff166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rmse: 356.11984534494525, Mean:  126821.34424850772\n"
     ]
    }
   ],
   "source": [
    "# Create polynomial features\n",
    "poly_features = PolynomialFeatures(degree = 3) #4 poziom najlepszy\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred_train1 = reg.predict(X_train_poly)\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_pred_train1 - y_train)**2))\n",
    "mean = mean_squared_error(y_train, y_pred_train1)\n",
    "print(f\"Rmse: {rmse}, Mean:  {mean}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56d809",
   "metadata": {},
   "source": [
    "## Task 5 Logistic regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdc65d3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1204\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[1;32m-> 1204\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1207\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\utils\\multiclass.py:218\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    210\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m ]:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_val = accuracy_score(y_val, y_pred)\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_pred - y_val)**2))\n",
    "mean = mean_squared_error(y_val, y_pred)\n",
    "#print(f\"Rmse: {rmse}, Mean:  {mean}\")\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ecd800",
   "metadata": {},
   "source": [
    "# task 6 diffrent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd059be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665     185.408548\n",
       "272     104.992946\n",
       "285      61.105704\n",
       "360      70.069745\n",
       "354     380.726517\n",
       "          ...     \n",
       "106    1605.224506\n",
       "270     185.240616\n",
       "860     164.856284\n",
       "435     181.831132\n",
       "102     172.825906\n",
       "Name: streams, Length: 571, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_1 = X_train[['bpm','key']]\n",
    "#data_2 = X_train.drop(['bpm','key'], axis = 1)\n",
    "#data_2\n",
    "X_train_1 = X_train[[ 'bpm','key']]\n",
    "X_val_1 = X_val[[ 'bpm','key']]\n",
    "X_train_2 = X_train.drop(['bpm','key'], axis = 1)\n",
    "X_val_2 = X_val.drop(['bpm','key'], axis = 1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6196e",
   "metadata": {},
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d9b74b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_train_1)\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_val_1)\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1204\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[1;32m-> 1204\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1207\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\utils\\multiclass.py:218\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    210\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m ]:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train_1, y_train)\n",
    "y_pred_train = clf.predict(X_train_1)\n",
    "y_pred = clf.predict(X_val_1)\n",
    "\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_val = accuracy_score(y_val, y_pred)\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_pred - y_val)**2))\n",
    "mean = mean_squared_error(y_val, y_pred)\n",
    "#print(f\"Rmse: {rmse}, Mean:  {mean}\")\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9b85e",
   "metadata": {},
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66da9b0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_train_2)\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_val_2)\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1204\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[1;32m-> 1204\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1207\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\utils\\multiclass.py:218\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    210\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m ]:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train_2, y_train)\n",
    "y_pred_train = clf.predict(X_train_2)\n",
    "y_pred = clf.predict(X_val_2)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_val = accuracy_score(y_val, y_pred)\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_pred - y_val)**2))\n",
    "mean = mean_squared_error(y_val, y_pred)\n",
    "#print(f\"Rmse: {rmse}, Mean:  {mean}\")\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")\n",
    "#czemu rmse i mean są inne  i co oznaczają"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57abcd",
   "metadata": {},
   "source": [
    "# task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60db5b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"winequality-red.csv\", sep  = \";\")\n",
    "X = data.drop(\"quality\", axis = 1)\n",
    "y = data[\"quality\"]\n",
    "\n",
    "X_train, X_help, y_train, y_help = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_help, y_help, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ac3b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf481641",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "201ac119",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Kernels: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#linear the best but the longest so most complicated\u001b[39;00m\n\u001b[0;32m      3\u001b[0m clf_SVM \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50000\u001b[39m )\n\u001b[1;32m----> 5\u001b[0m \u001b[43mclf_SVM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m clf_SVM\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf_SVM\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\svm\\_base.py:201\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    204\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    205\u001b[0m )\n\u001b[0;32m    206\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\svm\\_base.py:745\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    744\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 745\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32mH:\\CondaNavigator\\envs\\datasc\\lib\\site-packages\\sklearn\\utils\\multiclass.py:218\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    210\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m ]:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# Kernels: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} \n",
    "#linear the best but the longest so most complicated\n",
    "clf_SVM = svm.SVC(kernel='linear', C = 2, max_iter = 50000 )\n",
    "\n",
    "clf_SVM.fit(X_train, y_train)\n",
    "y_pred_train = clf_SVM.predict(X_train)\n",
    "y_pred = clf_SVM.predict(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_val = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444be28",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4686e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.6246648793565683, accuracy validation: 0.5545171339563862\n"
     ]
    }
   ],
   "source": [
    "#hidden_layer_sizes=(10, 5), random_state=1, max_iter=1000, solver='lbfgs'\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=1500,random_state=6, solver='adam', alpha =0.001)\n",
    "\n",
    "clf_mlp.fit(X_train, y_train)\n",
    "y_pred_train = clf_mlp.predict(X_train)\n",
    "y_pred = clf_mlp.predict(X_val)\n",
    "\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_val = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b9aabf",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3d344b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.773011617515639, accuracy validation: 0.4766355140186916\n"
     ]
    }
   ],
   "source": [
    "#dla distance accuracy 100%, dla knn mniejszych lepszy wynik # leaf nic nie robi\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=2, weights = \"uniform\", algorithm = \"ball_tree\", p = 10, leaf_size = 10000)\n",
    "\n",
    "clf_KNN.fit(X_train, y_train)\n",
    "y_pred_train = clf_KNN.predict(X_train)\n",
    "y_pred = clf_KNN.predict(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_val = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251ef7c",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20fdeb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5996425379803396, accuracy validation: 0.5327102803738317\n"
     ]
    }
   ],
   "source": [
    "clf_DT = tree.DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "clf_DT.fit(X_train, y_train)\n",
    "y_pred_train = clf_DT.predict(X_train)\n",
    "y_pred = clf_DT.predict(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_val = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507e1c3",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "117877e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.9803395889186773, accuracy validation: 0.6448598130841121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf_mlp1 = Pipeline([(\"scaler\", StandardScaler()), (\"mlp\", MLPClassifier(max_iter=5000, random_state=1, solver='adam', alpha =0.0001))])\n",
    "clf_mlp1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = clf_mlp1.predict(X_train)\n",
    "y_pred = clf_mlp1.predict(X_val)\n",
    "\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_val = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X_val, X_train], ignore_index=True)\n",
    "y_combined = pd.concat([y_val, y_train], ignore_index=True)\n",
    "\n",
    "#best for wine: \n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes = (40,20),max_iter=4500,random_state=4, solver='lbfgs', alpha =0.001)\n",
    "\n",
    "clf_mlp.fit(X_combined, y_combined)\n",
    "y_pred_train = clf_mlp.predict(X_combined)\n",
    "y_pred = clf_mlp.predict(X_test)\n",
    "\n",
    "\n",
    "acc_train = accuracy_score(y_combined, y_pred_train)\n",
    "acc_val = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy train: {acc_train}, accuracy validation: {acc_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
